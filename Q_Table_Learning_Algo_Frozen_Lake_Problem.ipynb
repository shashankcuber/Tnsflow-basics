{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q-Table Learning Algo Frozen Lake Problem.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashankcuber/Tnsflow-basics/blob/master/Q_Table_Learning_Algo_Frozen_Lake_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgZ0rvHyvU3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import gym\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFenmgWCGmyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#gym basic\n",
        "#making an gym environment CartPole\n",
        "env=gym.make('CartPole-v0')\n",
        "env.reset()\n",
        "#run an instance of env 1000 timesteps\n",
        "for _ in range(1000):\n",
        "  env.render()#provides the env\n",
        "  #take a random action in each step\n",
        "  env.step(env.action_space.sample())\n",
        "env.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzChzmgk1r_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env=gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipxKYY6C1xPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#implementing the q learning table to learn frozen lake environment\n",
        "#Initialize the table with all zeroes\n",
        "Q=np.zeros([env.observation_space.n,env.action_space.n])\n",
        "\n",
        "#setting the rate\n",
        "#learning rate\n",
        "lr=0.8\n",
        "#discount \n",
        "y=0.95\n",
        "num_episodes=2000\n",
        "\n",
        "#creating lists to contain total rewards and steps\n",
        "#jList[]\n",
        "rList=[]\n",
        "\n",
        "for i in range(num_episodes):\n",
        "  #reset the environment to get first few observation\n",
        "  s=env.reset()\n",
        "  rALl=0\n",
        "  d=False\n",
        "  j=0\n",
        "  \n",
        "  #Q-table learning Algorithm\n",
        "  \n",
        "  while j<99:\n",
        "    j+=1\n",
        "    #Choose an action by greedily (with noise) picking from the Q-Table\n",
        "    \n",
        "    a=np.argmax(Q[s,:]+np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
        "    #getting the new state and reward environment\n",
        "    s1,r,d,_=env.step(a)\n",
        "    #updating the Q Table with new knowledge\n",
        "    Q[s,a]=Q[s,a]+lr*(r+y*np.max(Q[s1,:])-Q[s,a])\n",
        "    \n",
        "    #calculating the cumulative total reward received \n",
        "    rALL+=r\n",
        "    #change to new state i.e s1\n",
        "    s=s1\n",
        "    \n",
        "    #if we have reached the goal\n",
        "    if(d==True):\n",
        "      break\n",
        "    \n",
        "    #append the reward in the list\n",
        "    rList.append(rALL)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yWFV_DFaAX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Score over time:\"+str(sum(rList))/num_episodes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9_MarZSabFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print the final Q values\n",
        "print \"Final Q-Table Values\"\n",
        "print Q"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}